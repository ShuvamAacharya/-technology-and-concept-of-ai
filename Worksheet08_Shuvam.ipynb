{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load the Wine dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 1. Train a Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "\n",
        "# 2. Train a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate F1 scores\n",
        "f1_dt = f1_score(y_test, y_pred_dt, average='weighted')\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "print(f\"Decision Tree F1 Score: {f1_dt:.4f}\")\n",
        "print(f\"Random Forest F1 Score: {f1_rf:.4f}\")\n",
        "\n",
        "# 3. Hyperparameter Tuning for Random Forest using GridSearchCV\n",
        "# Simplified hyperparameters for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [20, 50, 100],       # Number of trees in the forest\n",
        "    'max_depth': [5, 10, 20],            # Maximum depth of the trees\n",
        "    'min_samples_split': [2, 4, 6],       # Minimum samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4]         # Minimum samples required at each leaf node\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                           param_grid=param_grid, cv=5, n_jobs=-1, scoring='f1_weighted')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameters\n",
        "print(\"Best Hyperparameters for Random Forest:\", grid_search.best_params_)\n",
        "\n",
        "# Train the model with best hyperparameters\n",
        "best_rf_classifier = grid_search.best_estimator_\n",
        "y_pred_best_rf = best_rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate F1 score after tuning\n",
        "f1_best_rf = f1_score(y_test, y_pred_best_rf, average='weighted')\n",
        "print(f\"Best Random Forest F1 Score after Tuning: {f1_best_rf:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssu_3_exj3I7",
        "outputId": "aabed7b3-e461-45af-8053-5a1be0124079"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree F1 Score: 0.9628\n",
            "Random Forest F1 Score: 1.0000\n",
            "Best Hyperparameters for Random Forest: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Best Random Forest F1 Score after Tuning: 0.9816\n"
          ]
        }
      ]
    }
  ]
}